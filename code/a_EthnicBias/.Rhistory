par(mar=c(1.2,3,1,1),mgp=c(1.5,0.5,0),tcl=-0.3)
hist(kang_df$restricted_minus_proposed_TEST, #pch = 16,
#xlim = c(1.804,1.835),
col = rgb(1,0,0,0.5),
breaks=seq(-0.088, 0.08, length.out=30),
#cex=1.5,
xaxt='n',
xlim = c(-0.09, 0.08),
xlab = '',
#ylab = '(restricted-RMSE - proposed-RMSE)',
freq = F, border = 'white',
main = 'King County')
abline(v=0,  lty=5)
axis(1, at=seq(-0.09, 0.08, by = 0.02),  lwd.ticks=1)
#axis(1, at=seq(0 , 2000, by=200), lwd=0, lwd.ticks=1)
#par(mar=c(3,3,1.5,1),mgp=c(1.5,0.5,0),tcl=-0.3)
par(mar=c(1.2,3,1,1),mgp=c(1.5,0.5,0),tcl=-0.3)
hist(ny_df$restricted_minus_proposed_TEST, #pch = 16,
#xlim = c(1.804,1.835),
col =rgb(0,0,1, 0.5),
breaks=seq(-0.03, 0.03, length.out=15),
#cex=1.5,
xlim = c(-0.09, 0.08),
xaxt = 'n',
# xlab = '',
xlab = '',##'Proposed Predictive Degradation',
freq = F, border = 'white', add =F,
main =  'New York')
axis(1, at=seq(-0.09, 0.08, by = 0.02),  lwd.ticks=1)
abline(v=0,  lty=5)
plot(0,0, bty = 'n', xaxt='n', yaxt='n', ylim = c(1,2), xlim = c(1,2), ylab = '', xlab = '')
text(1.5,1.5,'Predictive Degradation', cex=1.1)
dev.off()
pdf("./figs/Kang_NY_RF_v_OLS.pdf", height=5,width=5)
cex_pt <- 0.5
par(mfrow=c(2,2),mar=c(3,3,2,1),mgp=c(1.5,0.5,0),tcl=-0.3)
## NYC
par(mar=c(3,3,2,1),mgp=c(1.5,0.5,0),tcl=-0.3)
plot(ny_df$Proposed_OLS_RMSE_test ,
ny_df$Proposed_RF_RMSE_test ,
xlab = 'Linear',
ylab = 'RF',
main = 'Proposed (New York)',
pch =  20,
cex = cex_pt,
col=rgb(0,0,0,0.4),
xlim = c(10.8,12.2),
ylim = c(10.8,12.2))
abline(a=0,b=1)
par(mar=c(3,2.5,2,1),mgp=c(1.5,0.5,0),tcl=-0.3)
plot(ny_df$Restricted_OLS_RMSE_test ,
ny_df$Restricted_RF_RMSE_test ,
xlab = 'Linear',
ylab = 'RF',
main = 'Restricted (New York)',
cex = cex_pt,
pch =  20,
col=rgb(0,0,0,0.4),
xlim = c(10.8,12.2),
ylim = c(10.8,12.2))
abline(a=0,b=1)
plot(kang_df$Proposed_OLS_RMSE_test ,
kang_df$Proposed_RF_RMSE_test ,
xlab = 'Linear',
ylab = 'RF',
main = 'Proposed (King County)',
pch = 20, cex = cex_pt,
col=rgb(0,0,0,0.4),
xlim = c(13.25,15.5),
ylim = c(13.25,15.5))
abline(a=0,b=1)
par(mar=c(3,2.5,2,1),mgp=c(1.5,0.5,0),tcl=-0.3)
plot(kang_df$Restricted_OLS_RMSE_test ,
kang_df$Restricted_RF_RMSE_test ,
xlab = 'Linear',
ylab = 'RF',
cex = cex_pt,
main = 'Restricted (King County)',
pch =  20,
col=rgb(0,0,0,0.4),
xlim = c(13.25,15.5),
ylim = c(13.25,15.5))
abline(a=0,b=1)
dev.off()
mean(kang_df$restricted_minus_proposed_TEST)
mean(ny_df$restricted_minus_proposed_TEST)
rm(list=ls())
library(data.table)
library(lubridate)
library(xtable)
library(lfe)
## Read data
dta <- fread("../data/NYData.csv")
## Descriptive statistics
n1 <- sum(dta$Asian==1)
n0 <- sum(dta$Asian==0)
n1
n0
t.test(SCORE ~ Asian, data=dta)
sd(dta$SCORE[dta$Asian==1])/sqrt(n1)
sd(dta$SCORE[dta$Asian==0])/sqrt(n0)
setwd('~/Dropbox/YelpBias/kristen_sandbox/final_paper_code/JITE_git_upload/Bias/code/a_EthnicBias/')
##
## Complaints vs. scores in NY data
##
rm(list=ls())
library(data.table)
library(lubridate)
library(xtable)
library(lfe)
## Read data
dta <- fread("../data/NYData.csv")
## Descriptive statistics
n1 <- sum(dta$Asian==1)
n0 <- sum(dta$Asian==0)
n1
n0
t.test(SCORE ~ Asian, data=dta)
sd(dta$SCORE[dta$Asian==1])/sqrt(n1)
sd(dta$SCORE[dta$Asian==0])/sqrt(n0)
getwd()
dta <- fread("../../data/NYData.csv")
##
## Complaints vs. scores in NY data
##
rm(list=ls())
library(data.table)
library(lubridate)
library(xtable)
library(lfe)
## Read data
dta <- fread("../../data/NYData.csv")
## Descriptive statistics
n1 <- sum(dta$Asian==1)
n0 <- sum(dta$Asian==0)
n1
n0
t.test(SCORE ~ Asian, data=dta)
sd(dta$SCORE[dta$Asian==1])/sqrt(n1)
sd(dta$SCORE[dta$Asian==0])/sqrt(n0)
t.test(avg.score ~ Asian, data=dta)
sd(dta$avg.score[dta$Asian==1])/sqrt(n1)
sd(dta$avg.score[dta$Asian==0])/sqrt(n0)
t.test(complaintBinary ~ Asian, data=dta)
sd(dta$complaintBinary[dta$Asian==1])/sqrt(n1)
sd(dta$complaintBinary[dta$Asian==0])/sqrt(n0)
all.boro <- unique(dta$BORO)
n.boro <- length(all.boro)
boro.tab <- data.frame(matrix(NA, n.boro,7))
for(i in 1:n.boro){
boro.tab[i,1] <- all.boro[i]
my.t <- t.test((dta$BORO==all.boro[i]) ~ dta$Asian)
boro.tab[i,2] <- my.t$estimate[2]*100
p1 <- mean(dta$BORO==all.boro[i] & dta$Asian==1)
boro.tab[i,3] <- sqrt(p1 * (1-p1) /nrow(dta))*100
boro.tab[i,4] <- my.t$estimate[1]*100
p0 <- mean(dta$BORO==all.boro[i] & dta$Asian==0)
boro.tab[i,5] <- sqrt(p0 * (1-p0)/nrow(dta))*100
boro.tab[i,6] <- my.t$p.value
boro.tab[i,7] <- sum(dta$BORO==all.boro[i])
}
print(xtable(boro.tab[,1:6], digits = c(0,0,2,2,2,2,2)), include.rownames=FALSE)
all.zip <- unique(dta$ZIPCODE)
n.zip <- length(all.zip)
zip.tab <-  data.frame(matrix(NA, n.zip,7))
for(i in 1:n.zip){
zip.tab[i,1] <- all.zip[i]
my.t <- t.test((dta$ZIPCODE==all.zip[i]) ~ dta$Asian)
zip.tab[i,2] <- my.t$estimate[2]*100
p1 <- mean(dta$ZIPCODE==all.zip[i] & dta$Asian==1)
zip.tab[i,3] <- sqrt(p1 * (1-p1)/nrow(dta))*100
zip.tab[i,4] <- my.t$estimate[1]*100
p0 <- mean(dta$ZIPCODE==all.zip[i] & dta$Asian==0)
zip.tab[i,5] <- sqrt(p0 * (1-p0)/nrow(dta))*100
zip.tab[i,6] <- my.t$p.value
zip.tab[i,7] <- sum(dta$ZIPCODE==all.zip[i])
}
zip.tab <- zip.tab[order(zip.tab[,7], decreasing=T),]
print(xtable(zip.tab[zip.tab[,7]>1000,1:6], digits = c(0,0,2,2,2,2,2)), include.rownames=FALSE)
n1 <- sum(dta$Asian==1)
n0 <- sum(dta$Asian==0)
n1
n0
colnames(dta)
13533+58547
length(unique(dta$CAMIS))
length(unique(dta$DBA))
length(unique(dta$pk))
head(dta)
length(unique(dta$CAMIS))
mean(dta$Asian)
dta$CAMIS[dta$Asian==1]
length(unique(dta$CAMIS[dta$Asian==1]))
length(unique(dta$CAMIS[dta$Asian==0]))
length(unique(dta$CAMIS))
3880/20630
16750/20630
t.test(SCORE ~ Asian, data=dta)
sd(dta$SCORE[dta$Asian==1])/sqrt(n1)
sd(dta$SCORE[dta$Asian==0])/sqrt(n0)
t.test(SCORE ~ Asian, data=dta)
sd(dta$SCORE[dta$Asian==1])/sqrt(n1)
sd(dta$SCORE[dta$Asian==0])/sqrt(n0)
t.test(avg.score ~ Asian, data=dta)
sd(dta$avg.score[dta$Asian==1])/sqrt(n1)
sd(dta$avg.score[dta$Asian==0])/sqrt(n0)
t.test(complaintBinary ~ Asian, data=dta)
sd(dta$complaintBinary[dta$Asian==1])/sqrt(n1)
sd(dta$complaintBinary[dta$Asian==0])/sqrt(n0)
t.test(SCORE ~ Asian, data=dta)
sd(dta$SCORE[dta$Asian==1])/sqrt(n1)
sd(dta$SCORE[dta$Asian==0])/sqrt(n0)
##
## Complaints vs. scores in NY data
##
rm(list=ls())
library(data.table)
library(lubridate)
library(xtable)
library(lfe)
## Read data
dta <- fread("../../data/NYData.csv")
## Descriptive statistics
n1 <- sum(dta$Asian==1)
n0 <- sum(dta$Asian==0)
n1
n0
t.test(SCORE ~ Asian, data=dta)
sd(dta$SCORE[dta$Asian==1])/sqrt(n1)
sd(dta$SCORE[dta$Asian==0])/sqrt(n0)
t.test(avg.score ~ Asian, data=dta)
sd(dta$avg.score[dta$Asian==1])/sqrt(n1)
sd(dta$avg.score[dta$Asian==0])/sqrt(n0)
t.test(complaintBinary ~ Asian, data=dta)
sd(dta$complaintBinary[dta$Asian==1])/sqrt(n1)
sd(dta$complaintBinary[dta$Asian==0])/sqrt(n0)
all.boro <- unique(dta$BORO)
n.boro <- length(all.boro)
boro.tab <- data.frame(matrix(NA, n.boro,7))
for(i in 1:n.boro){
boro.tab[i,1] <- all.boro[i]
my.t <- t.test((dta$BORO==all.boro[i]) ~ dta$Asian)
boro.tab[i,2] <- my.t$estimate[2]*100
p1 <- mean(dta$BORO==all.boro[i] & dta$Asian==1)
boro.tab[i,3] <- sqrt(p1 * (1-p1) /nrow(dta))*100
boro.tab[i,4] <- my.t$estimate[1]*100
p0 <- mean(dta$BORO==all.boro[i] & dta$Asian==0)
boro.tab[i,5] <- sqrt(p0 * (1-p0)/nrow(dta))*100
boro.tab[i,6] <- my.t$p.value
boro.tab[i,7] <- sum(dta$BORO==all.boro[i])
}
print(xtable(boro.tab[,1:6], digits = c(0,0,2,2,2,2,2)), include.rownames=FALSE)
## ZIP codes
all.zip <- unique(dta$ZIPCODE)
n.zip <- length(all.zip)
zip.tab <-  data.frame(matrix(NA, n.zip,7))
for(i in 1:n.zip){
zip.tab[i,1] <- all.zip[i]
my.t <- t.test((dta$ZIPCODE==all.zip[i]) ~ dta$Asian)
zip.tab[i,2] <- my.t$estimate[2]*100
p1 <- mean(dta$ZIPCODE==all.zip[i] & dta$Asian==1)
zip.tab[i,3] <- sqrt(p1 * (1-p1)/nrow(dta))*100
zip.tab[i,4] <- my.t$estimate[1]*100
p0 <- mean(dta$ZIPCODE==all.zip[i] & dta$Asian==0)
zip.tab[i,5] <- sqrt(p0 * (1-p0)/nrow(dta))*100
zip.tab[i,6] <- my.t$p.value
zip.tab[i,7] <- sum(dta$ZIPCODE==all.zip[i])
}
zip.tab <- zip.tab[order(zip.tab[,7], decreasing=T),]
print(xtable(zip.tab[zip.tab[,7]>1000,1:6], digits = c(0,0,2,2,2,2,2)), include.rownames=FALSE)
my.breaks <- seq(0,max(dta$SCORE),by=2)
bin.labels <- 1:(length(my.breaks)-1)
dta$bin <- as.numeric(cut(dta$SCORE, breaks=my.breaks, labels=bin.labels, include.lowest=T))
complaint.agg <- aggregate(complaint ~ bin + Asian, data=dta, FUN=mean)
count.agg <- aggregate(rep(1,nrow(dta)) ~ bin + Asian, data=dta, FUN=sum)
complaint.agg$count <- count.agg[,3]
complaint.agg$se <- complaint.agg$complaint * (1-complaint.agg$complaint) / sqrt(complaint.agg$count)
par(mar=c(3,3,2,1), mgp=c(1.5,0.5,0), tcl=-0.3)
plot(complaint.agg$bin[complaint.agg$Asian==0],
complaint.agg$complaint[complaint.agg$Asian==0], xlim=c(0,20),
ylim=c(0, 0.07),
axes=F,
pch=16, cex=sqrt(complaint.agg$count[complaint.agg$Asian==0]/pi)*0.1,
col=rgb(0,0,0,0.4), xlab="Inspection Score", ylab="Complaint", main="Inspection Score and 311 Complaint")
points(complaint.agg$bin[complaint.agg$Asian==1],
complaint.agg$complaint[complaint.agg$Asian==1],col="black",
pch=1, cex=sqrt(complaint.agg$count[complaint.agg$Asian==1]/pi)*0.1, lwd=1)
text(2.5,0.03, "Non-Asian",cex=0.8)
text(5, 0.06, "Asian",cex=0.8,col="black")
axis(1, at=bin.labels-0.5, labels=my.breaks[1:(length(my.breaks)-1)])
axis(2)
box()
help(felm)
lfe0 <- felm(complaint ~ Asian | 0 | 0 | CAMIS, data = dta)
lfe1 <- felm(complaint ~ Asian + I(SCORE/100) + I(avg.score/100) | 0 | 0 | CAMIS, data = dta)
lfe2 <- felm(complaint ~ Asian + I(SCORE/100) + I(avg.score/100) | year  | 0 | CAMIS, data = dta)
lfe3 <- felm(complaint ~ Asian + I(SCORE/100) + I(avg.score/100) | year + BORO | 0 | CAMIS, data = dta)
lfe4 <- felm(complaint ~ Asian + I(SCORE/100) + I(avg.score/100) | year + ZIPCODE | 0 | CAMIS, data = dta)
summary(lfe0)
lfe0 <- felm(complaint ~ Asian | 0 | 0 | CAMIS, data = dta)
lfe1 <- felm(complaint ~ Asian + I(SCORE/100) + I(avg.score/100) | 0 | 0 | CAMIS, data = dta)
lfe2 <- felm(complaint ~ Asian + I(SCORE/100) + I(avg.score/100) | year  | 0 | CAMIS, data = dta)
lfe3 <- felm(complaint ~ Asian + I(SCORE/100) + I(avg.score/100) | year + BORO | 0 | CAMIS, data = dta)
lfe4 <- felm(complaint ~ Asian + I(SCORE/100) + I(avg.score/100) | year + ZIPCODE | 0 | CAMIS, data = dta)
summary(lfe0)
summary(lfe1)
summary(lfe2)
summary(lfe3)
summary(lfe4)
table(dta$complaint)
table(dta$complaintBinary)
lfe0 <- felm(complaintBinary ~ Asian | 0 | 0 | CAMIS, data = dta)
summary(lfe0)
my.breaks <- seq(0,max(dta$SCORE),by=2)
bin.labels <- 1:(length(my.breaks)-1)
dta$bin <- as.numeric(cut(dta$SCORE, breaks=my.breaks, labels=bin.labels, include.lowest=T))
complaint.agg <- aggregate(complaintBinary ~ bin + Asian, data=dta, FUN=mean)
count.agg <- aggregate(rep(1,nrow(dta)) ~ bin + Asian, data=dta, FUN=sum)
complaint.agg$count <- count.agg[,3]
complaint.agg$se <- complaint.agg$complaint * (1-complaint.agg$complaint) / sqrt(complaint.agg$count)
par(mar=c(3,3,2,1), mgp=c(1.5,0.5,0), tcl=-0.3)
plot(complaint.agg$bin[complaint.agg$Asian==0],
complaint.agg$complaint[complaint.agg$Asian==0], xlim=c(0,20),
ylim=c(0, 0.07),
axes=F,
pch=16, cex=sqrt(complaint.agg$count[complaint.agg$Asian==0]/pi)*0.1,
col=rgb(0,0,0,0.4), xlab="Inspection Score", ylab="Complaint", main="Inspection Score and 311 Complaint")
points(complaint.agg$bin[complaint.agg$Asian==1],
complaint.agg$complaint[complaint.agg$Asian==1],col="black",
pch=1, cex=sqrt(complaint.agg$count[complaint.agg$Asian==1]/pi)*0.1, lwd=1)
text(2.5,0.03, "Non-Asian",cex=0.8)
text(5, 0.06, "Asian",cex=0.8,col="black")
axis(1, at=bin.labels-0.5, labels=my.breaks[1:(length(my.breaks)-1)])
axis(2)
box()
##
## Analysis of potential ethnic bias in King County data
##
##=========================================
##  SETTING UP DATA
##=========================================
## Clearing memory
rm(list=ls())
## Packages
library(data.table) #to read in larger datasets more effectively
library(lfe) # clustered SEs in OLS
library(clusterSEs) # clustered SEs for GLM
library(xtable)
## Read in data
dta <- fread("../../../../../KangData/instances_mergerd_seattle.csv", verbose=F)
#dta <- fread("../../data/instances_mergerd_seattle.csv", verbose=F)
## Augment year
year <- as.numeric(substr(dta$inspection_period_end_date,start=1,stop=4))
dta <- data.frame(dta, year=year)
## One coding error
dta$inspection_prev_penalty_score[which(dta$inspection_prev_penalty_score==-1)] <- 0
dta$inspection_average_prev_penalty_scores[which(dta$inspection_average_prev_penalty_scores==-1)] <- 0
getwd()
setwd("/Users/kristen/Dropbox/YelpBias/kristen_sandbox/final_paper_code/JITE_git_upload/Bias/code")
dta <- fread("../../../../../../KangData/instances_mergerd_seattle.csv", verbose=F)
dta <- fread("../../../../../KangData/instances_mergerd_seattle.csv", verbose=F)
getwd()
setwd("/Users/kristen/Dropbox/YelpBias/kristen_sandbox/final_paper_code/JITE_git_upload/Bias/code/a_EthnicBias/")
## Clearing memory
rm(list=ls())
## Packages
library(data.table) #to read in larger datasets more effectively
library(lfe) # clustered SEs in OLS
library(clusterSEs) # clustered SEs for GLM
library(xtable)
## Read in data
dta <- fread("../../../../../KangData/instances_mergerd_seattle.csv", verbose=F)
#dta <- fread("../../data/instances_mergerd_seattle.csv", verbose=F)
dta <- fread("../../../../../../KangData/instances_mergerd_seattle.csv", verbose=F)
## Augment year
year <- as.numeric(substr(dta$inspection_period_end_date,start=1,stop=4))
dta <- data.frame(dta, year=year)
## One coding error
dta$inspection_prev_penalty_score[which(dta$inspection_prev_penalty_score==-1)] <- 0
dta$inspection_average_prev_penalty_scores[which(dta$inspection_average_prev_penalty_scores==-1)] <- 0
##
## Identify terms that indicate food poisoning (see NYC Yelp piece)
##
poison <- as.numeric(grepl("food poisoning",dta$review_contents))
vomit <- as.numeric(grepl("vomit",dta$review_contents))
diarrhea <- as.numeric(grepl("diarrhea", dta$review_contents))
sick <- as.numeric(grepl("sick", dta$review_contents))
homesick <- as.numeric(grepl("homesick", dta$review_contents))
sick2 <- as.numeric(sick==1 & homesick==0)
dta <- data.frame(dta, poison = poison, vomit = vomit, diarrhea = diarrhea, sick = sick,
sick2=sick2)
## Foodborne illness indicators
fbi <- as.numeric((poison+vomit+diarrhea+sick)>0)
fbi2 <- as.numeric((poison+vomit+diarrhea+sick2)>0)
## Augmenting data frame
dta <- data.frame(dta, poison = poison, vomit = vomit, diarrhea = diarrhea, sick = sick,
sick2=sick2, fbi = fbi, fbi2 = fbi2)
##
## Cuisine classification
##
cuisines <- unique(dta$cuisines)
cuisines <- gsub("\\[|\\]|'","", cuisines)
cuisines <- strsplit(cuisines,", ")
cuisines <- unique(unlist(cuisines))
## Formatting as a matrix
cuisine.mat <- data.frame(matrix(NA, nrow(dta), length(cuisines)))
names(cuisine.mat) <- cuisines
for(i in 1:length(cuisines)){
cuisine.mat[,i] <- as.numeric(grepl(cuisines[i], dta$cuisines))
}
## Manually augment cuisines with "Asian" and "ethnic"
labels <- read.csv("../data/cuisines.csv", header=T, as.is=T)
labels <- read.csv("../../data/cuisines.csv", header=T, as.is=T)
## Simple indicator of Asian / Ethnic restaurant
##
asian <- as.numeric(apply(cuisine.mat[,labels$asian==1],1,sum)>0)
ethnic <- as.numeric(apply(cuisine.mat[,labels$ethnic==1],1,sum)>0)
## Augmenting data frame
dta <- data.frame(dta, asian = asian, ethnic = ethnic)
n1 <- sum(dta$asian==1)
n0 <- sum(dta$asian==0)
n1
n0
mean(dta$inspection_prev_penalty_score[dta$asian==1])
sd(dta$inspection_prev_penalty_score[dta$asian==1])/sqrt(n1)
mean(dta$inspection_prev_penalty_score[dta$asian==0])
sd(dta$inspection_prev_penalty_score[dta$asian==0])/sqrt(n0)
t.test(dta$inspection_prev_penalty_score ~ I(dta$asian==1))
mean(dta$inspection_average_prev_penalty_scores[dta$asian==1])
sd(dta$inspection_average_prev_penalty_scores[dta$asian==1])/sqrt(n1)
mean(dta$inspection_average_prev_penalty_scores[dta$asian==0])
sd(dta$inspection_average_prev_penalty_scores[dta$asian==0])/sqrt(n0)
t.test(dta$inspection_average_prev_penalty_scores ~ I(dta$asian==1))
mean(dta$review_count[dta$asian==1])
sd(dta$review_count[dta$asian==1])/sqrt(n1)
mean(dta$review_count[dta$asian==0])
sd(dta$review_count[dta$asian==0])/sqrt(n0)
t.test(review_count ~ I(asian==1), data=dta)
mean(dta$average_review_rating[dta$asian==1])
sd(dta$average_review_rating[dta$asian==1])/sqrt(n1)
mean(dta$average_review_rating[dta$asian==0])
sd(dta$average_review_rating[dta$asian==0])/sqrt(n0)
t.test(average_review_rating ~ I(asian==1), data=dta)
## Zip code imbalance
all.zip <- unique(dta$zip_code)
n.zip <- length(all.zip)
zip.mat <- matrix(NA, nrow(dta), n.zip)
for(i in 1:n.zip){
zip.mat[,i] <- as.numeric(dta$zip_code==all.zip[i])
}
zip.mat <- data.frame(zip.mat)
names(zip.mat) <- paste("zip",all.zip, sep="")
dta <- data.frame(dta, zip.mat)
## Balance table
tab.out <- matrix(NA, n.zip, 7)
for(i in 1:n.zip){
my.t <- t.test(zip.mat[,i] ~ dta$asian)
tab.out[i,1] <- all.zip[i]
tab.out[i,2] <- my.t$estimate[2]*100
p1 <- mean(zip.mat[,i]==1 & asian==1)
tab.out[i,3] <- sqrt(p1 * (1-p1)/nrow(dta))*100
tab.out[i,4] <- my.t$estimate[1]*100
p0 <- mean(zip.mat[,i]==1 & asian==0)
tab.out[i,5] <- sqrt(p0 * (1-p0)/nrow(dta))*100
tab.out[i,6] <- my.t$p.value
tab.out[i,7] <- sum(zip.mat[,i])
}
tab.out <- tab.out[order(tab.out[,7], decreasing=T),]
tab.out <- data.frame(tab.out)
## Binning to visualize data points
all.scores <- seq(min(dta$inspection_average_prev_penalty_scores),
max(dta$inspection_average_prev_penalty_scores), length=1000)
bin.cuts <- c(seq(0,35, by=2),90)
k.bin <- length(bin.cuts)-1
store <- matrix(NA, k.bin, 5)
for(i in 1:k.bin){
which.sub <- dta$inspection_average_prev_penalty_scores>= bin.cuts[i] &
dta$inspection_average_prev_penalty_scores < bin.cuts[i+1]
dta.sub <- dta[which.sub,]
store[i,1] <- mean(dta.sub$fbi[dta.sub$asian==0])
store[i,2] <- mean(dta.sub$fbi[dta.sub$asian==1])
store[i,3] <- sum(dta.sub$asian==0)
store[i,4] <- sum(dta.sub$asian==1)
store[i,5] <- sum(bin.cuts[i]+bin.cuts[i+1])/2
}
## Fixing up final bin (so that all data is displayed)
store[k.bin,5] <- 34
store <- data.frame(store)
names(store) <- c("mean.nonasian","mean.asian", "n.nonasian", "n.asian", "mid")
## Plotting
par(mar=c(3,3,2,1), mgp=c(1.5,0.5,0),tcl=-0.3)
plot(store$mid, store[,1],type="n",ylim=c(0.035,0.15),xlim=c(0,35),
main="Inspection Score and Food Poisoning Review", xlab="Inspection score", ylab="Probability of term")
points(store$mid, store$mean.nonasian,cex=sqrt(store$n.nonasian/pi)*0.2,col=rgb(0,0,0,0.4),pch=16)
points(store$mid, store$mean.asian,cex=sqrt(store$n.asian/pi)*0.2,col="black", pch=1)
text(6, 0.11, "Asian",col="black")
text(5, 0.05, "Non-Asian")
table(dta$fbi2)
m0 <-glm(fbi2 ~ asian, family="binomial", data=dta)
summary(m0)
m1 <- glm(fbi2 ~ asian + inspection_prev_penalty_score + review_count + as.factor(year), family="binomial", data=dta)
summary(m1)
m2 <- glm(fbi2 ~ asian + inspection_average_prev_penalty_scores + review_count + as.factor(year), family="binomial", data=dta)
summary(m2)
m3 <- glm(fbi2 ~ asian + inspection_average_prev_penalty_scores + review_count + average_review_rating + as.factor(year), family="binomial", data=dta)
summary(m3)
m4 <- glm(fbi2 ~ asian + inspection_average_prev_penalty_scores + review_count + average_review_rating + as.factor(zip_code) + as.factor(year), family="binomial", data=dta)
summary(m4)
bsse1 = (m1c$ci[, 2] - m1c$ci[, 1]) / (2 * 1.96)
exp(0.016)
1.016129 - 1
(1.016129 - 1)/1
