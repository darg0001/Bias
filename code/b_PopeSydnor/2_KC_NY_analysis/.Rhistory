names(x) <- sheets
x
}
setwd("./output/")
file.list <- list.files(pattern='*.xlsx')
file.list <- file.list[grep('a1b_PAPER_*',file.list)]
df.list <- lapply(file.list, read_excel_allsheets)
## initialize df for storing -- left panel
df_displace <- data.frame()
df_displace <- data.frame(displace=numeric(),
RF_degradation=numeric(),
OLS_degradation=numeric())
for(i in 1:length(df.list)){
tmp1 <- df.list[[i]]
for(j in 1:length(tmp1)){
tmp <- tmp1[[j]]
tmp <- tmp[(tmp$delta_SUP_CP==1) &
(tmp$shift_sd_record==1)  &
(((tmp$Beta1_SAP==1) & (tmp$Beta2_CP==1) & (tmp$Beta3_SUP==5))),]
df_displace_add <- data.frame(displace=tmp$displace_record,
RF_degradation=tmp$RMSE_Restricted_DT_test - tmp$RMSE_Proposed_DT_test,
OLS_degradation=tmp$RMSE_Restricted_OLS_test - tmp$RMSE_Proposed_OLS_test)
df_displace <- rbind(df_displace, df_displace_add)
}
}
## then aggregating by displace: compute 5th/95th-stats
head(df_displace)
table(df_displace$displace) ## spot-check we should have 100 in each b/c we did 100 simulations for each configuration across displace parameter
## RF
percentile_5th_RF <- aggregate(RF_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_RF <-aggregate(RF_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.95))
## OLS
percentile_5th_OLS <- aggregate(OLS_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_OLS <-aggregate(OLS_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.95))
df_percentile <- merge(percentile_5th_RF,
percentile_95th_RF,
by = 'displace',
how ='left')
df_percentile <- merge(df_percentile,
percentile_5th_OLS,
by = 'displace',
how ='left')
df_percentile <- merge(df_percentile,
percentile_95th_OLS,
by = 'displace',
how ='left')
## initialize df for storing -- left panel
df_mean_variance <- data.frame()
df_mean_variance <- data.frame(shift_sd_record=numeric(),
beta3=numeric(),
RF_degradation=numeric())
file.list <- list.files(pattern='*.xlsx')
file.list <- file.list[grep('a2a_*',file.list)]
df.list <-lapply(file.list, read_excel_allsheets)
for(i in 1:length(df.list)){
tmp1 <- df.list[[i]]
for(j in 1:length(tmp1)){
tmp <- tmp1[[j]]
idx <- which(tmp$Beta3_SUP==1)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
idx <- which(tmp$Beta3_SUP==5)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
idx <- which(tmp$Beta3_SUP==10)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
}
}
## spot-check -- that we have 100 in the grid
table(df_mean_variance$beta3, df_mean_variance$shift_sd_record)
## now again -- create aggregate percentiles for each \beta3 x shift_sd_record combo
## RF
percentile_5th_RF <- aggregate(RF_degradation ~ beta3 + shift_sd_record, data = df_mean_variance, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_RF <-aggregate(RF_degradation ~ beta3 + shift_sd_record, data = df_mean_variance, FUN = function(x) quantile(x, probs = 0.95))
df_percentile_beta3 <- merge(percentile_5th_RF,
percentile_95th_RF,
by = c('beta3','shift_sd_record'),
how ='left')
head(df_percentile_beta3)
ls
## 6/19/2018
rm(list=ls())
library(readxl)
library(latex2exp)
library(calibrate)
library(readxl)
read_excel_allsheets <- function(filename, tibble = FALSE) {
# I prefer straight data.frames
# but if you like tidyverse tibbles (the default with read_excel)
# then just pass tibble = TRUE
sheets <- readxl::excel_sheets(filename)
x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
if(!tibble) x <- lapply(x, as.data.frame)
names(x) <- sheets
x
}
setwd("./output/")
setwd('~/Dropbox/YelpBias/kristen_sandbox/final_paper_code/JITE_git_upload/Bias/code/b_PopeSydnor/1_MC_simulations/')
## 6/19/2018
rm(list=ls())
library(readxl)
library(latex2exp)
library(calibrate)
library(readxl)
read_excel_allsheets <- function(filename, tibble = FALSE) {
# I prefer straight data.frames
# but if you like tidyverse tibbles (the default with read_excel)
# then just pass tibble = TRUE
sheets <- readxl::excel_sheets(filename)
x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
if(!tibble) x <- lapply(x, as.data.frame)
names(x) <- sheets
x
}
setwd("./output/")
## 6/19/2018
rm(list=ls())
library(readxl)
library(latex2exp)
library(calibrate)
library(readxl)
read_excel_allsheets <- function(filename, tibble = FALSE) {
# I prefer straight data.frames
# but if you like tidyverse tibbles (the default with read_excel)
# then just pass tibble = TRUE
sheets <- readxl::excel_sheets(filename)
x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
if(!tibble) x <- lapply(x, as.data.frame)
names(x) <- sheets
x
}
setwd("./output/")
file.list <- list.files(pattern='*.xlsx')
file.list <- file.list[grep('a1b_PAPER_*',file.list)]
df.list <- lapply(file.list, read_excel_allsheets)
## initialize df for storing -- left panel
df_displace <- data.frame()
df_displace <- data.frame(displace=numeric(),
RF_degradation=numeric(),
OLS_degradation=numeric())
for(i in 1:length(df.list)){
tmp1 <- df.list[[i]]
for(j in 1:length(tmp1)){
tmp <- tmp1[[j]]
tmp <- tmp[(tmp$delta_SUP_CP==1) &
(tmp$shift_sd_record==1)  &
(((tmp$Beta1_SAP==1) & (tmp$Beta2_CP==1) & (tmp$Beta3_SUP==5))),]
df_displace_add <- data.frame(displace=tmp$displace_record,
RF_degradation=tmp$RMSE_Restricted_DT_test - tmp$RMSE_Proposed_DT_test,
OLS_degradation=tmp$RMSE_Restricted_OLS_test - tmp$RMSE_Proposed_OLS_test)
df_displace <- rbind(df_displace, df_displace_add)
}
}
## then aggregating by displace: compute 5th/95th-stats
head(df_displace)
table(df_displace$displace) ## spot-check we should have 100 in each b/c we did 100 simulations for each configuration across displace parameter
## RF
percentile_5th_RF <- aggregate(RF_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_RF <-aggregate(RF_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.95))
## OLS
percentile_5th_OLS <- aggregate(OLS_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_OLS <-aggregate(OLS_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.95))
df_percentile <- merge(percentile_5th_RF,
percentile_95th_RF,
by = 'displace',
how ='left')
df_percentile <- merge(df_percentile,
percentile_5th_OLS,
by = 'displace',
how ='left')
df_percentile <- merge(df_percentile,
percentile_95th_OLS,
by = 'displace',
how ='left')
## initialize df for storing -- left panel
df_mean_variance <- data.frame()
df_mean_variance <- data.frame(shift_sd_record=numeric(),
beta3=numeric(),
RF_degradation=numeric())
file.list <- list.files(pattern='*.xlsx')
file.list <- file.list[grep('a2a_*',file.list)]
df.list <-lapply(file.list, read_excel_allsheets)
for(i in 1:length(df.list)){
tmp1 <- df.list[[i]]
for(j in 1:length(tmp1)){
tmp <- tmp1[[j]]
idx <- which(tmp$Beta3_SUP==1)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
idx <- which(tmp$Beta3_SUP==5)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
idx <- which(tmp$Beta3_SUP==10)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
}
}
## spot-check -- that we have 100 in the grid
table(df_mean_variance$beta3, df_mean_variance$shift_sd_record)
## now again -- create aggregate percentiles for each \beta3 x shift_sd_record combo
## RF
percentile_5th_RF <- aggregate(RF_degradation ~ beta3 + shift_sd_record, data = df_mean_variance, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_RF <-aggregate(RF_degradation ~ beta3 + shift_sd_record, data = df_mean_variance, FUN = function(x) quantile(x, probs = 0.95))
df_percentile_beta3 <- merge(percentile_5th_RF,
percentile_95th_RF,
by = c('beta3','shift_sd_record'),
how ='left')
head(df_percentile_beta3)
setwd('~/Dropbox/YelpBias/kristen_sandbox/final_paper_code/simulation_epsilon_revised/output/')
## initialize df for storing -- left panel
df_displace <- data.frame()
df_displace <- data.frame(displace=numeric(),
RF_degradation=numeric(),
OLS_degradation=numeric())
for(i in 1:length(df.list)){
tmp1 <- df.list[[i]]
for(j in 1:length(tmp1)){
tmp <- tmp1[[j]]
tmp <- tmp[(tmp$delta_SUP_CP==1) &
(tmp$shift_sd_record==1)  &
(((tmp$Beta1_SAP==1) & (tmp$Beta2_CP==1) & (tmp$Beta3_SUP==5))),]
df_displace_add <- data.frame(displace=tmp$displace_record,
RF_degradation=tmp$RMSE_Restricted_DT_test - tmp$RMSE_Proposed_DT_test,
OLS_degradation=tmp$RMSE_Restricted_OLS_test - tmp$RMSE_Proposed_OLS_test)
df_displace <- rbind(df_displace, df_displace_add)
}
}
## then aggregating by displace: compute 5th/95th-stats
head(df_displace)
table(df_displace$displace) ## spot-check we should have 100 in each b/c we did 100 simulations for each configuration across displace parameter
## RF
percentile_5th_RF <- aggregate(RF_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_RF <-aggregate(RF_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.95))
## OLS
percentile_5th_OLS <- aggregate(OLS_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_OLS <-aggregate(OLS_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.95))
df_percentile <- merge(percentile_5th_RF,
percentile_95th_RF,
by = 'displace',
how ='left')
df_percentile <- merge(df_percentile,
percentile_5th_OLS,
by = 'displace',
how ='left')
df_percentile <- merge(df_percentile,
percentile_95th_OLS,
by = 'displace',
how ='left')
## initialize df for storing -- left panel
df_mean_variance <- data.frame()
df_mean_variance <- data.frame(shift_sd_record=numeric(),
beta3=numeric(),
RF_degradation=numeric())
file.list <- list.files(pattern='*.xlsx')
file.list <- file.list[grep('a2a_*',file.list)]
df.list <-lapply(file.list, read_excel_allsheets)
for(i in 1:length(df.list)){
tmp1 <- df.list[[i]]
for(j in 1:length(tmp1)){
tmp <- tmp1[[j]]
idx <- which(tmp$Beta3_SUP==1)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
idx <- which(tmp$Beta3_SUP==5)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
idx <- which(tmp$Beta3_SUP==10)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
}
}
## spot-check -- that we have 100 in the grid
table(df_mean_variance$beta3, df_mean_variance$shift_sd_record)
## now again -- create aggregate percentiles for each \beta3 x shift_sd_record combo
## RF
percentile_5th_RF <- aggregate(RF_degradation ~ beta3 + shift_sd_record, data = df_mean_variance, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_RF <-aggregate(RF_degradation ~ beta3 + shift_sd_record, data = df_mean_variance, FUN = function(x) quantile(x, probs = 0.95))
df_percentile_beta3 <- merge(percentile_5th_RF,
percentile_95th_RF,
by = c('beta3','shift_sd_record'),
how ='left')
head(df_percentile_beta3)
file.list <- list.files(pattern='*.xlsx')
file.list <- file.list[grep('a1b_PAPER_*',file.list)]
df.list <- lapply(file.list, read_excel_allsheets)
## initialize df for storing -- left panel
df_displace <- data.frame()
df_displace <- data.frame(displace=numeric(),
RF_degradation=numeric(),
OLS_degradation=numeric())
for(i in 1:length(df.list)){
tmp1 <- df.list[[i]]
for(j in 1:length(tmp1)){
tmp <- tmp1[[j]]
tmp <- tmp[(tmp$delta_SUP_CP==1) &
(tmp$shift_sd_record==1)  &
(((tmp$Beta1_SAP==1) & (tmp$Beta2_CP==1) & (tmp$Beta3_SUP==5))),]
df_displace_add <- data.frame(displace=tmp$displace_record,
RF_degradation=tmp$RMSE_Restricted_DT_test - tmp$RMSE_Proposed_DT_test,
OLS_degradation=tmp$RMSE_Restricted_OLS_test - tmp$RMSE_Proposed_OLS_test)
df_displace <- rbind(df_displace, df_displace_add)
}
}
## then aggregating by displace: compute 5th/95th-stats
head(df_displace)
table(df_displace$displace) ## spot-check we should have 100 in each b/c we did 100 simulations for each configuration across displace parameter
## RF
percentile_5th_RF <- aggregate(RF_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_RF <-aggregate(RF_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.95))
## OLS
percentile_5th_OLS <- aggregate(OLS_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_OLS <-aggregate(OLS_degradation ~ displace, data = df_displace, FUN = function(x) quantile(x, probs = 0.95))
df_percentile <- merge(percentile_5th_RF,
percentile_95th_RF,
by = 'displace',
how ='left')
df_percentile <- merge(df_percentile,
percentile_5th_OLS,
by = 'displace',
how ='left')
df_percentile <- merge(df_percentile,
percentile_95th_OLS,
by = 'displace',
how ='left')
## initialize df for storing -- left panel
df_mean_variance <- data.frame()
df_mean_variance <- data.frame(shift_sd_record=numeric(),
beta3=numeric(),
RF_degradation=numeric())
file.list <- list.files(pattern='*.xlsx')
file.list <- file.list[grep('a2a_*',file.list)]
df.list <-lapply(file.list, read_excel_allsheets)
for(i in 1:length(df.list)){
tmp1 <- df.list[[i]]
for(j in 1:length(tmp1)){
tmp <- tmp1[[j]]
idx <- which(tmp$Beta3_SUP==1)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
idx <- which(tmp$Beta3_SUP==5)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
idx <- which(tmp$Beta3_SUP==10)
df_mean_variance_add <- data.frame(shift_sd_record=tmp$shift_sd_record[idx],
beta3=tmp$Beta3_SUP[idx],
RF_degradation=tmp$RMSE_Restricted_DT_test[idx] - tmp$RMSE_Proposed_DT_test[idx])
df_mean_variance <- rbind(df_mean_variance, df_mean_variance_add)
}
}
## spot-check -- that we have 100 in the grid
table(df_mean_variance$beta3, df_mean_variance$shift_sd_record)
## now again -- create aggregate percentiles for each \beta3 x shift_sd_record combo
## RF
percentile_5th_RF <- aggregate(RF_degradation ~ beta3 + shift_sd_record, data = df_mean_variance, FUN = function(x) quantile(x, probs = 0.05))
percentile_95th_RF <-aggregate(RF_degradation ~ beta3 + shift_sd_record, data = df_mean_variance, FUN = function(x) quantile(x, probs = 0.95))
df_percentile_beta3 <- merge(percentile_5th_RF,
percentile_95th_RF,
by = c('beta3','shift_sd_record'),
how ='left')
head(df_percentile_beta3)
y_axis_label <- 'Predictive Degradation'
layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE), widths = c(2,2), heights = c(0.1,1))
par(mar=c(0.5,3,0.5,1),mgp=c(1.5,0.5,0),tcl=-0.3)
plot(0,0, bty = 'n', xaxt='n', yaxt='n', ylim = c(1,2), xlim = c(1,2), ylab = '', xlab = '')
text(1.5,1.5,'Effect of SAP Displacement', cex=1.4)
par(mar=c(3,3,2,1),mgp=c(1.5,0.5,0),tcl=-0.1)
par(cex.lab=1.2)
plot(100,100,
pch = '.',
col = rgb(0,0,0,0.4),#rgb(1,0,0,0.4),
cex=3,
ylim = c(-2, 0.7),
xlim = c(0.07, 1.93),
ylab=y_axis_label,#'',#'(Restricted-RMSE) - (Proposed-RMSE)',
xlab = expression(eta), main = TeX("mean displacement ($\\eta$)"))
abline(h=0, col=rgb(0,0,0,0.4),lty=5)
polygon(c(df_percentile$displace, rev(df_percentile$displace)),
c(df_percentile$RF_degradation.x, rev(df_percentile$RF_degradation.y)),
#lty = "dashed",
border = NA,
lwd = 2,
col = rgb(0,0,0,0.2))
text(1.25, -0.58, 'Random Forest', col='Black', adj = c(0,0))
polygon(c(df_percentile$displace, rev(df_percentile$displace)),
c(df_percentile$OLS_degradation.x, rev(df_percentile$OLS_degradation.y)),
#lty = "solid", lwd = 2,
border = NA,
col = rgb(0,0,0,0.6))
text(1.25, 0.32, 'Linear Regression', col='Black', adj = c(0,0))
par(mar=c(3,1,2,1),mgp=c(1.5,0.5,0),tcl=-0.3)
par(cex.lab=1.2)
plot(100,100,
xlim =c(0.23, 0.97),
ylim = c(-2, 0.7),
cex = 4,
col=rgb(0,0,0,0.1),#rgb(1,0,0,0.1),
pch = '.',
xlab = expression(sigma), main = TeX("mean-variance displacement ($\\sigma$)"), #'mean-variance displacement ', #expression('\sigma'),
ylab='')
abline(h=0, col=rgb(0,0,0,0.4),lty=5)
head(df_percentile_beta3)
idx <- which(df_percentile_beta3$beta3==1 & df_percentile_beta3$shift_sd_record==1)
polygon(c(df_percentile_beta3$shift_sd_record[idx], rev(df_percentile_beta3$shift_sd_record[idx])),
c(df_percentile_beta3$RF_degradation.x[idx], rev(df_percentile_beta3$RF_degradation.y[idx])),
#lty = "longdash", lwd = 2,
border = NA,
col = rgb(0,0,0,0.9))
idx <- which(df_percentile_beta3$beta3==1 )
polygon(c(df_percentile_beta3$shift_sd_record[idx], rev(df_percentile_beta3$shift_sd_record[idx])),
c(df_percentile_beta3$RF_degradation.x[idx], rev(df_percentile_beta3$RF_degradation.y[idx])),
#lty = "longdash", lwd = 2,
border = NA,
col = rgb(0,0,0,0.9))
text(0.22, 0.4, expression(beta[3]==1), col = rgb(0,0,0,0.9), cex = 1.1, adj = c(0,0))
idx <- which(df_percentile_beta3$beta3==5)
polygon(c(df_percentile_beta3$shift_sd_record[idx], rev(df_percentile_beta3$shift_sd_record[idx])),
# 6/23/2018
#Plot NY vs. KC results for Predictive Degradation and comparing OLS vs. RF (Restricted/Proposed Approaches)
rm(list=ls())
#setwd('~/Dropbox/YelpBias/kristen_sandbox/final_paper_code/JITE_git_upload/Bias/code/b_PopeSydnor/2_KC_NY_analysis/')
## King County
kang_df1 <- read.csv('./output/Kang_output_additional_Features_meanSUP_1.csv')
kang_df2 <- read.csv('./output/Kang_output_additional_Features_meanSUP_2.csv')
kang_df3 <- read.csv('./output/Kang_output_additional_Features_meanSUP_3.csv')
kang_df4 <- read.csv('./output/Kang_output_additional_Features_meanSUP_4.csv')
kang_df <- rbind(kang_df1, kang_df2, kang_df3, kang_df4)
## Predictive Degradation
kang_df$restricted_minus_proposed_TEST <- kang_df$Restricted_RF_RMSE_test - kang_df$Proposed_RF_RMSE_test
kang_df$restricted_minus_proposed_TEST_OLS <- kang_df$Restricted_OLS_RMSE_test - kang_df$Proposed_OLS_RMSE_test
mean(kang_df$restricted_minus_proposed_TEST)
#1] -0.0165316
# 6/23/2018
#Plot NY vs. KC results for Predictive Degradation and comparing OLS vs. RF (Restricted/Proposed Approaches)
rm(list=ls())
setwd('~/Dropbox/YelpBias/kristen_sandbox/final_paper_code/JITE_git_upload/Bias/code/b_PopeSydnor/2_KC_NY_analysis/')
## King County
kang_df1 <- read.csv('./output/Kang_output_additional_Features_meanSUP_1.csv')
kang_df2 <- read.csv('./output/Kang_output_additional_Features_meanSUP_2.csv')
kang_df3 <- read.csv('./output/Kang_output_additional_Features_meanSUP_3.csv')
kang_df4 <- read.csv('./output/Kang_output_additional_Features_meanSUP_4.csv')
kang_df <- rbind(kang_df1, kang_df2, kang_df3, kang_df4)
## Predictive Degradation
kang_df$restricted_minus_proposed_TEST <- kang_df$Restricted_RF_RMSE_test - kang_df$Proposed_RF_RMSE_test
kang_df$restricted_minus_proposed_TEST_OLS <- kang_df$Restricted_OLS_RMSE_test - kang_df$Proposed_OLS_RMSE_test
mean(kang_df$restricted_minus_proposed_TEST)
#1] -0.0165316
ny_df1 <- read.csv('./output/NYC_output_all_years_additional_features_meanSUP_1.csv')
ny_df2 <- read.csv('./output/NYC_output_all_years_additional_features_meanSUP_2.csv')
ny_df3 <- read.csv('./output/NYC_output_all_years_additional_features_meanSUP_3.csv')
ny_df4 <- read.csv('./output/NYC_output_all_years_additional_features_meanSUP_4.csv')
ny_df <- rbind(ny_df1, ny_df2, ny_df3, ny_df4)
## Predictive Degradation
ny_df$restricted_minus_proposed_TEST <- ny_df$Restricted_RF_RMSE_test - ny_df$Proposed_RF_RMSE_test
ny_df$restricted_minus_proposed_TEST_OLS <- ny_df$Restricted_OLS_RMSE_test - ny_df$Proposed_OLS_RMSE_test
mean(ny_df$restricted_minus_proposed_TEST)
#[1] 0.0029749
getwd()
rm(list = ls())
## compute relative % decrease in RMSE when adding CP to model for King County
kang_df_rmse <- read.csv('./output/Kang_output_record_model_with_and_without_keywords.csv')
# for RF
mean(( kang_df_rmse$Full_RF_RMSE_test_without_CP - kang_df_rmse$Full_RF_RMSE_test )/ kang_df_rmse$Full_RF_RMSE_test) * 100
#[1] 0.003388043
mean(( kang_df_rmse$Full_RF_RMSE_train_without_CP - kang_df_rmse$Full_RF_RMSE_train )/ kang_df_rmse$Full_RF_RMSE_train) * 100
#[1] -0.0003659654
## compute relative % decrease in RMSE when adding CP to model for New York
ny_df_rmse <- read.csv('./output/NYC_output_with_without_complaints.csv')
# for RF
mean(( ny_df_rmse$Full_RF_RMSE_test_without_CP - ny_df_rmse$Full_RF_RMSE_test )/ ny_df_rmse$Full_RF_RMSE_test) * 100
#[1] 0.01822071
mean(( ny_df_rmse$Full_RF_RMSE_train_without_CP - ny_df_rmse$Full_RF_RMSE_train )/ ny_df_rmse$Full_RF_RMSE_train) * 100
#[1] 0.2227397
( ny_df_rmse$Full_RF_RMSE_test_without_CP - ny_df_rmse$Full_RF_RMSE_test )/ ny_df_rmse$Full_RF_RMSE_test
mean(( ny_df_rmse$Full_RF_RMSE_test_without_CP - ny_df_rmse$Full_RF_RMSE_test )/ ny_df_rmse$Full_RF_RMSE_test_without_CP) * 100
mean(( ny_df_rmse$Full_RF_RMSE_train_without_CP - ny_df_rmse$Full_RF_RMSE_train )/ ny_df_rmse$Full_RF_RMSE_train_without_CP) * 100
mean(( kang_df_rmse$Full_RF_RMSE_test_without_CP - kang_df_rmse$Full_RF_RMSE_test )/ kang_df_rmse$Full_RF_RMSE_test_without_CP) * 100
mean(( kang_df_rmse$Full_RF_RMSE_train_without_CP - kang_df_rmse$Full_RF_RMSE_train )/ kang_df_rmse$Full_RF_RMSE_train_without_CP) * 100
rm(list = ls())
## compute relative % decrease in RMSE when adding CP to model for King County
## compute: without_CP - with_CP / without_CP * 100
kang_df_rmse <- read.csv('./output/Kang_output_record_model_with_and_without_keywords.csv')
# for RF
mean(( kang_df_rmse$Full_RF_RMSE_test_without_CP - kang_df_rmse$Full_RF_RMSE_test )/ kang_df_rmse$Full_RF_RMSE_test_without_CP) * 100
mean(( kang_df_rmse$Full_RF_RMSE_train_without_CP - kang_df_rmse$Full_RF_RMSE_train )/ kang_df_rmse$Full_RF_RMSE_train_without_CP) * 100
## compute relative % decrease in RMSE when adding CP to model for New York
ny_df_rmse <- read.csv('./output/NYC_output_with_without_complaints.csv')
# for RF
mean(( ny_df_rmse$Full_RF_RMSE_test_without_CP - ny_df_rmse$Full_RF_RMSE_test )/ ny_df_rmse$Full_RF_RMSE_test_without_CP) * 100
mean(( ny_df_rmse$Full_RF_RMSE_train_without_CP - ny_df_rmse$Full_RF_RMSE_train )/ ny_df_rmse$Full_RF_RMSE_train_without_CP) * 100
